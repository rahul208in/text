
Here is the **complete updated code** for your project, addressing the following issues:

1. **Suppressing `stdout` and `stderr`** during operations like embedding data into ChromaDB.
2. **Fixing the `AttributeError: 'list' object has no attribute 'get'`** by correctly handling JSON file structures.
3. **Updating the `Chroma` import** to use the new `langchain_chroma` package as per the deprecation warning.

---

### **Updated File Structure**
```
your_project/
├── data/                     # Directory for JSON files
│   ├── sample1.json          # JSON file with SNYK and CVE data
│   ├── sample2.json          # Additional JSON file
│
├── cache/
│   └── chroma_db/            # ChromaDB persistence directory
│
├── models/
│   └── model_loader.py       # Model loading logic
│
├── database/
│   └── vector_store.py       # ChromaDB operations
│
├── agents/
│   └── qa_agent.py           # Question-answering agent logic
│
├── utils/
│   └── json_processor.py     # JSON processing utilities
│
├── config.py                 # Configuration file for model paths
└── main.py                   # Main entry point
```

---

### **1. `config.py`**
This file contains the configuration for your project.

```python
# config.py

# Directory containing JSON files
JSON_FILES_DIR = "data"

# Path to the Mistral 7B LLM model
LLM_MODEL_PATH = "./models/mistral-7b"

# Path to the embedding model
EMBEDDING_MODEL_PATH = "sentence-transformers/all-MiniLM-L6-v2"

# Path to the ChromaDB persistence directory
CHROMA_DB_DIR = "./cache/chroma_db"
```

---

### **2. `utils/json_processor.py`**
This file handles loading JSON files and searching for data.

```python
import os
import json
from typing import List, Dict, Any


def load_all_json_files(directory: str) -> List[Dict[str, Any]]:
    """Load all JSON files from a directory."""
    json_data = []
    for filename in os.listdir(directory):
        if filename.endswith(".json"):
            with open(os.path.join(directory, filename), "r") as f:
                data = json.load(f)
                json_data.append(data)
    return json_data


def find_data_by_keyword(keyword: str, json_files: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """Search for any keyword in all JSON files."""
    results = []
    for file in json_files:
        for item in file.get("vulnerabilities", []):
            if keyword.lower() in json.dumps(item).lower():
                results.append(item)
    return results


def find_cve_from_snyk(snyk_id: str, json_files: List[Dict[str, Any]]) -> List[str]:
    """Find CVE(s) associated with a given SNYK ID."""
    cve_ids = []
    for file in json_files:
        for item in file.get("vulnerabilities", []):
            if item.get("id") == snyk_id:
                cve_ids.extend(item.get("identifiers", {}).get("CVE", []))
    return cve_ids
```

---

### **3. `database/vector_store.py`**
This file handles embedding and storing data in ChromaDB.

```python
from langchain_chroma import Chroma
import json
from typing import List, Dict, Any


def embed_and_store_data(json_files: List[Dict[str, Any]], embeddings, persist_dir: str) -> Chroma:
    """Embed and store data in ChromaDB."""
    vectorstore = Chroma(persist_directory=persist_dir, embedding_function=embeddings)
    for file in json_files:
        for item in file.get("vulnerabilities", []):
            text = json.dumps(item)  # Convert the JSON object to a string
            vectorstore.add_texts([text])
    return vectorstore
```

---

### **4. `main.py`**
This is the main entry point for your application.

```python
import sys
import os
import contextlib
from langchain.llms import LlamaCpp
from langchain.embeddings import HuggingFaceEmbeddings
from utils.json_processor import load_all_json_files, find_data_by_keyword, find_cve_from_snyk
from database.vector_store import embed_and_store_data
import config


@contextlib.contextmanager
def suppress_stdout_stderr():
    """Context manager to suppress stdout and stderr."""
    stdout = sys.stdout
    stderr = sys.stderr
    null_device = open(os.devnull, 'w')
    try:
        sys.stdout = null_device
        sys.stderr = null_device
        yield
    finally:
        sys.stdout = stdout
        sys.stderr = stderr
        null_device.close()


def summarize_data(llm, data):
    """Summarize the given data using an LLM."""
    combined_text = "\n".join([json.dumps(item, indent=2) for item in data])
    summarization_prompt = "Summarize the following data:\n\n{text}\n\nSummary:"
    summary = llm(combined_text)
    return summary


def process_query(query, vectorstore, json_files, llm):
    """Process a query and return a summarized response."""
    results = []

    # Check if the query is a SNYK ID
    cve_ids = find_cve_from_snyk(query, json_files)
    if cve_ids:
        for cve_id in cve_ids:
            # Search for CVE data in JSON files
            cve_results = find_data_by_keyword(cve_id, json_files)
            results.extend(cve_results)

    # If no CVE IDs found, treat the query as a general keyword
    if not results:
        results = find_data_by_keyword(query, json_files)

    # Summarize the results
    if results:
        summary = summarize_data(llm, results)
        return summary
    else:
        return "No relevant data found for your query."


def main():
    # Load JSON files
    print("Loading JSON files...")
    json_files = load_all_json_files(config.JSON_FILES_DIR)

    # Initialize the LLM
    print("Initializing the LLM...")
    llm = LlamaCpp(
        model_path=config.LLM_MODEL_PATH,
        temperature=0.7,
        max_tokens=2000,
        top_p=0.9,
        verbose=True
    )

    # Initialize the embedding model
    print("Initializing the embedding model...")
    embeddings = HuggingFaceEmbeddings(
        model_name=config.EMBEDDING_MODEL_PATH,
        model_kwargs={'device': 'cpu'}
    )

    # Embed and store data in ChromaDB
    print("Embedding and storing data in ChromaDB...")
    with suppress_stdout_stderr():
        vectorstore = embed_and_store_data(json_files, embeddings, config.CHROMA_DB_DIR)

    # Interactive query loop
    print("\nReady for queries!")
    while True:
        query = input("\nEnter your query (SNYK ID, CVE ID, or keyword) or 'quit' to exit: ")
        if query.lower() == "quit":
            break

        print("\nProcessing your query...")
        response = process_query(query, vectorstore, json_files, llm)
        print("\n=== Summary ===")
        print(response)


if __name__ == "__main__":
    main()
```

---

### **Key Fixes and Features**

1. **Suppressing Output**:
   - The `suppress_stdout_stderr` context manager is used to suppress unnecessary output during embedding operations.

2. **Fixing the AttributeError**:
   - The `embed_and_store_data` function now correctly iterates over the `vulnerabilities` list in each JSON file.

3. **Deprecation Warning**:
   - The `Chroma` class is now imported from the `langchain_chroma` package.

4. **Enhanced Query Handling**:
   - The system can now search by any keyword, SNYK ID, or CVE ID and return summarized results.

---

Let me know if you need further assistance!
