
To address the issue of re-embedding data every time the program starts, we can implement a mechanism to check if the data has changed before embedding it into ChromaDB. This will avoid unnecessary re-embedding and improve performance.

Hereâ€™s how we can achieve this:

---

### **Solution Overview**
1. **Hashing JSON Files**:
   - Compute a hash of the JSON files' contents to detect changes.
   - Store the hash in a metadata file (e.g., `hashes.json`).

2. **Compare Hashes**:
   - On program startup, compare the current hash of each JSON file with the stored hash.
   - Only re-embed files that have changed or are new.

3. **Update Hashes**:
   - After embedding, update the metadata file with the new hashes.

---

### **Updated Code**

#### **1. `database/vector_store.py`**
This updated function includes logic to check for changes in JSON files before embedding.

```python
import os
import json
import hashlib
from langchain_chroma import Chroma
from typing import List, Any


def calculate_file_hash(file_path: str) -> str:
    """Calculate the hash of a file's contents."""
    hasher = hashlib.sha256()
    with open(file_path, "rb") as f:
        hasher.update(f.read())
    return hasher.hexdigest()


def load_hashes(hash_file: str) -> dict:
    """Load stored hashes from a file."""
    if os.path.exists(hash_file):
        with open(hash_file, "r") as f:
            return json.load(f)
    return {}


def save_hashes(hash_file: str, hashes: dict):
    """Save hashes to a file."""
    with open(hash_file, "w") as f:
        json.dump(hashes, f, indent=4)


def embed_and_store_data(
    json_files: List[str], embeddings, persist_dir: str, hash_file: str
) -> Chroma:
    """Embed and store data in ChromaDB, only for changed or new files."""
    vectorstore = Chroma(persist_directory=persist_dir, embedding_function=embeddings)

    # Load existing hashes
    stored_hashes = load_hashes(hash_file)
    current_hashes = {}

    for file_path in json_files:
        # Calculate the current hash of the file
        current_hash = calculate_file_hash(file_path)
        current_hashes[file_path] = current_hash

        # Check if the file has changed or is new
        if file_path not in stored_hashes or stored_hashes[file_path] != current_hash:
            print(f"Embedding data from {file_path} (new or changed)...")
            with open(file_path, "r") as f:
                data = json.load(f)

                # Handle both dict and list structures
                if isinstance(data, dict):
                    for item in data.get("vulnerabilities", []):
                        text = json.dumps(item)
                        vectorstore.add_texts([text])
                elif isinstance(data, list):
                    for item in data:
                        text = json.dumps(item)
                        vectorstore.add_texts([text])
        else:
            print(f"Skipping {file_path} (no changes detected).")

    # Save updated hashes
    save_hashes(hash_file, current_hashes)

    return vectorstore
```

---

#### **2. `main.py`**
Update the `main.py` file to use the new `embed_and_store_data` function.

```python
import sys
import os
import contextlib
from langchain.llms import LlamaCpp
from langchain.embeddings import HuggingFaceEmbeddings
from utils.json_processor import load_all_json_files
from database.vector_store import embed_and_store_data
import config


@contextlib.contextmanager
def suppress_stdout_stderr():
    """Context manager to suppress stdout and stderr."""
    stdout = sys.stdout
    stderr = sys.stderr
    null_device = open(os.devnull, "w")
    try:
        sys.stdout = null_device
        sys.stderr = null_device
        yield
    finally:
        sys.stdout = stdout
        sys.stderr = stderr
        null_device.close()


def main():
    # Load JSON files
    print("Loading JSON files...")
    json_files = [
        os.path.join(config.JSON_FILES_DIR, f)
        for f in os.listdir(config.JSON_FILES_DIR)
        if f.endswith(".json")
    ]

    # Initialize the LLM
    print("Initializing the LLM...")
    with suppress_stdout_stderr():
        llm = LlamaCpp(
            model_path=config.LLM_MODEL_PATH,
            temperature=0.7,
            max_tokens=2000,
            top_p=0.9,
            verbose=True,
        )

    # Initialize the embedding model
    print("Initializing the embedding model...")
    embeddings = HuggingFaceEmbeddings(
        model_name=config.EMBEDDING_MODEL_PATH, model_kwargs={"device": "cpu"}
    )

    # Embed and store data in ChromaDB
    print("Embedding and storing data in ChromaDB...")
    with suppress_stdout_stderr():
        vectorstore = embed_and_store_data(
            json_files, embeddings, config.CHROMA_DB_DIR, "hashes.json"
        )

    print("Data embedding completed successfully!")

    # Interactive query loop
    print("\nReady for queries!")
    while True:
        query = input("\nEnter your query (SNYK ID, CVE ID, or keyword) or 'quit' to exit: ")
        if query.lower() == "quit":
            break

        print("\nProcessing your query...")
        # Add your query processing logic here
        print("\n=== Summary ===")
        print("Query processing not implemented yet.")


if __name__ == "__main__":
    main()
```

---

### **How It Works**

1. **Hash Calculation**:
   - Each JSON file's hash is calculated using the `calculate_file_hash` function.

2. **Hash Comparison**:
   - The current hash of each file is compared with the stored hash in `hashes.json`.
   - If the file is new or has changed, it is re-embedded into ChromaDB.

3. **Hash Storage**:
   - After embedding, the updated hashes are saved back to `hashes.json`.

4. **Skipping Unchanged Files**:
   - Files that have not changed are skipped, avoiding unnecessary re-embedding.

---

### **Testing the Solution**

1. **Initial Run**:
   - Run the program with a set of JSON files. All files will be embedded, and their hashes will be stored in `hashes.json`.

2. **Subsequent Runs**:
   - Run the program again without modifying the files. The program should skip embedding for all files.

3. **File Modification**:
   - Modify one of the JSON files and run the program. Only the modified file should be re-embedded.

4. **New Files**:
   - Add a new JSON file and run the program. The new file should be embedded.

---

### **Expected Output**

- On the first run:
  ```
  Embedding data from sample1.json (new or changed)...
  Embedding data from sample2.json (new or changed)...
  Data embedding completed successfully!
  ```

- On subsequent runs (without changes):
  ```
  Skipping sample1.json (no changes detected).
  Skipping sample2.json (no changes detected).
  Data embedding completed successfully!
  ```

- After modifying a file:
  ```
  Skipping sample1.json (no changes detected).
  Embedding data from sample2.json (new or changed)...
  Data embedding completed successfully!
  ```

---

Let me know if you encounter any issues or need further assistance!
