
### **Understanding Your Requirements**

From your detailed explanation and the provided screenshots, here is a clear understanding of your requirements:

1. **Data Embedding and Storage**:
   - All JSON files should be embedded and stored in ChromaDB.
   - Each document should include metadata such as `CVE ID`, `SNYK ID`, `description`, and `affected versions`.

2. **Query Handling**:
   - Queries should be embedded and searched in ChromaDB.
   - If matches are found, all matching results should be passed to the LLM for summarization.

3. **Summary Generation**:
   - The summary must include:
     - `CVE ID`
     - `SNYK ID`
     - `Description` (if available)
     - `Affected Versions` (if available)
   - The summary should be concise but detailed enough to understand the issue.

4. **Error Handling**:
   - Handle cases where some fields (e.g., `description`, `affected versions`) are missing.
   - Fix issues like `AttributeError: 'list' object has no attribute 'get'` and `TypeError: Object of type Document is not JSON serializable`.

5. **Preserve Functionality**:
   - Ensure the system works for all query types (`SNYK ID`, `CVE ID`, or keywords).

---

### **Proposed Solution**

The solution involves:
1. **Fixing the `embed_and_store_data` function**:
   - Handle JSON files with varying structures.
   - Ensure metadata is correctly extracted and stored in ChromaDB.

2. **Improving Query Processing**:
   - Embed the query and search in ChromaDB.
   - Pass all matching results to the LLM for summarization.

3. **Enhancing Summarization**:
   - Include `CVE ID`, `SNYK ID`, `description`, and `affected versions` in the summary.
   - Handle missing fields gracefully.

---

### **Updated Code Implementation**

#### **`main.py`**
```python
import os
from langchain.llms import LlamaCpp
from models.model_loader import CustomEmbeddings
from database.vector_store import embed_and_store_data, search_in_chromadb
from utils.json_processor import load_all_json_files
import config

def summarize_data(llm, data):
    """Summarize the retrieved data using the LLM."""
    summaries = []
    for item in data:
        cve_id = item.get("CVE ID", "N/A")
        snyk_id = item.get("id", "N/A")
        description = item.get("title", "No description available.")
        affected_versions = ", ".join(item.get("semver", {}).get("vulnerable", [])) or "N/A"
        summaries.append(
            f"CVE ID: {cve_id}\nSNYK ID: {snyk_id}\nDescription: {description}\nAffected Versions: {affected_versions}"
        )

    # Combine summaries and pass to the LLM for a concise summary
    combined_text = "\n\n".join(summaries)
    prompt = f"Summarize the following data concisely:\n\n{combined_text}\n\nSummary (include CVE ID, SNYK ID, description, and affected versions):"
    return llm.invoke(prompt)

def process_query(query, vectorstore, llm):
    """Process the user query and return results."""
    # Search in ChromaDB
    results = search_in_chromadb(query, vectorstore)
    if results:
        # Extract metadata from results
        data = [result.metadata for result in results]
        return summarize_data(llm, data)

    return "No relevant data found for your query."

def main():
    # Load JSON files
    print("Loading JSON files...")
    json_files = load_all_json_files(config.JSON_FILES_DIR)

    # Initialize the LLM
    print("Initializing the LLM...")
    llm = LlamaCpp(model_path=config.LLM_MODEL_PATH, temperature=0.7, max_tokens=200, top_p=0.9, verbose=True)

    # Initialize the embedding model
    print("Initializing the embedding model...")
    embeddings = CustomEmbeddings(config.EMBEDDING_MODEL_PATH)

    # Embed and store data in ChromaDB
    print("Embedding and storing data in ChromaDB...")
    vectorstore = embed_and_store_data(json_files, embeddings, config.CHROMA_DB_DIR)
    print("Data embedding completed successfully!")

    # Interactive query loop
    print("\nReady for queries!")
    while True:
        query = input("Enter your query (SNYK ID, CVE ID, or keyword) or 'quit' to exit: ")
        if query.lower() == "quit":
            break

        print("\nProcessing your query...")
        summary = process_query(query, vectorstore, llm)
        print(f"\nSummary:\n{summary}")

if __name__ == "__main__":
    main()
```

---

#### **`database/vector_store.py`**
```python
from langchain_chroma import Chroma
import json

def embed_and_store_data(json_files, embeddings, persist_dir):
    """Embed and store data in ChromaDB."""
    vectorstore = Chroma(persist_directory=persist_dir, embedding_function=embeddings)
    for file in json_files:
        if isinstance(file, dict) and "vulnerabilities" in file:
            for item in file["vulnerabilities"]:
                text = json.dumps(item)  # Convert the JSON object to a string
                metadata = {
                    "CVE ID": item.get("CVE ID", "N/A"),
                    "id": item.get("id", "N/A"),
                    "title": item.get("title", "No description available."),
                    "semver": item.get("semver", {}),
                }
                vectorstore.add_texts([text], metadatas=[metadata])
        elif isinstance(file, list):
            for item in file:
                text = json.dumps(item)  # Convert the JSON object to a string
                metadata = {
                    "CVE ID": item.get("CVE ID", "N/A"),
                    "id": item.get("id", "N/A"),
                    "title": item.get("title", "No description available."),
                    "semver": item.get("semver", {}),
                }
                vectorstore.add_texts([text], metadatas=[metadata])
        else:
            text = json.dumps(file)  # Convert the JSON object to a string
            metadata = {
                "CVE ID": "N/A",
                "id": "N/A",
                "title": "No description available.",
                "semver": {},
            }
            vectorstore.add_texts([text], metadatas=[metadata])
    return vectorstore

def search_in_chromadb(query, vectorstore):
    """Search for the query in ChromaDB."""
    return vectorstore.similarity_search(query, k=5)
```

---

#### **`models/model_loader.py`**
```python
from sentence_transformers import SentenceTransformer

class CustomEmbeddings:
    """Custom wrapper for SentenceTransformer to add embed_query and embed_documents methods."""
    def __init__(self, model_path: str):
        self.model = SentenceTransformer(model_path)

    def embed_query(self, query: str):
        return self.model.encode(query, convert_to_tensor=False).tolist()

    def embed_documents(self, documents: list):
        return [self.model.encode(doc, convert_to_tensor=False).tolist() for doc in documents]
```

---

#### **`utils/json_processor.py`**
```python
import json
import os

def load_all_json_files(directory):
    """Load all JSON files from a directory."""
    json_files = []
    for filename in os.listdir(directory):
        if filename.endswith(".json"):
            with open(os.path.join(directory, filename), "r") as file:
                json_files.append(json.load(file))
    return json_files
```

---

#### **`config.py`**
```python
import os

# Paths
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
JSON_FILES_DIR = os.path.join(BASE_DIR, "data")
CHROMA_DB_DIR = os.path.join(BASE_DIR, "cache", "chroma_db")
LLM_MODEL_PATH = "/path/to/your/mistral-7b-model"  # Update with your Mistral model path
EMBEDDING_MODEL_PATH = "/Users/rj22898/Documents/model/Embedded/gte-large"  # Path to gte-large model
```

---

### **Key Features**

1. **Data Embedding**:
   - All JSON files are embedded and stored in ChromaDB with metadata (`CVE ID`, `SNYK ID`, `description`, and `affected versions`).

2. **Query Handling**:
   - Queries are embedded and searched in ChromaDB.
   - Results are passed to the LLM for summarization.

3. **Summary Generation**:
   - Summaries include `CVE ID`, `SNYK ID`, `description`, and `affected versions`.

4. **Error Handling**:
   - Handles missing fields gracefully.

---

### **Testing Steps**

1. **Test Data Embedding**:
   - Verify that all JSON files are embedded and stored in ChromaDB.

2. **Test Query Handling**:
   - Test with `SNYK ID`, `CVE ID`, and keywords to ensure correct results.

3. **Test Summary Generation**:
   - Verify that summaries include `CVE ID`, `SNYK ID`, `description`, and `affected versions`.

4. **Test Edge Cases**:
   - Test with invalid inputs or queries with no matches.

---

Let me know if you encounter any issues!
