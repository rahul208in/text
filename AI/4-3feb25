
Yes, we can optimize this by checking if the ChromaDB already contains the data and only initializing/loading when necessary. Here's the optimized version:

```python
# main.py

import os
import sys
import contextlib
import hashlib
import json
from pathlib import Path
from config import JSON_FILES_DIR, CHROMA_DB_DIR, LLM_MODEL_PATH, EMBEDDING_MODEL_PATH
from utils.json_processor import load_all_json_files, extract_text_from_json
from database.vector_store import initialize_chroma_db, add_documents_to_vectorstore
from langchain.llms import LlamaCpp
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate

@contextlib.contextmanager
def suppress_stdout():
    """Context manager to suppress stdout and stderr."""
    stdout = sys.stdout
    old_stderr = sys.stderr
    null_device = open(os.devnull, 'w')
    try:
        sys.stdout = null_device
        sys.stderr = null_device
        yield
    finally:
        sys.stdout = stdout
        sys.stderr = old_stderr
        null_device.close()

def calculate_documents_hash(documents):
    """Calculate a hash of all documents to check for changes."""
    combined_text = "".join(documents)
    return hashlib.md5(combined_text.encode()).hexdigest()

def save_hash(hash_value):
    """Save hash to a file."""
    with open(os.path.join(CHROMA_DB_DIR, "documents_hash.txt"), "w") as f:
        f.write(hash_value)

def load_hash():
    """Load previously saved hash."""
    hash_file = os.path.join(CHROMA_DB_DIR, "documents_hash.txt")
    if os.path.exists(hash_file):
        with open(hash_file, "r") as f:
            return f.read().strip()
    return None

def initialize_llm():
    """Initialize the LLM with suppressed output."""
    with suppress_stdout():
        llm = LlamaCpp(
            model_path=LLM_MODEL_PATH,
            temperature=0.75,
            max_tokens=2000,
            top_p=1,
            verbose=True,
        )
    return llm

def setup_qa_chain(vectorstore):
    """Setup QA chain with strict prompt."""
    llm = initialize_llm()

    strict_prompt = """Use the following pieces of context to answer the question at the end.
If you don't know the answer, just say "I don't know." Do not attempt to answer questions unrelated to the context.

{context}

Question: {question}
Answer:"""

    prompt_template = PromptTemplate(
        template=strict_prompt, input_variables=["context", "question"]
    )

    with suppress_stdout():
        qa_chain = RetrievalQA.from_chain_type(
            llm=llm,
            chain_type="stuff",
            retriever=vectorstore.as_retriever(),
            return_source_documents=True,
            chain_type_kwargs={"prompt": prompt_template},
            verbose=True
        )

    return qa_chain

def initialize_or_load_vectorstore():
    """Initialize or load existing vectorstore."""
    print("Checking existing database...")

    # Create directory if it doesn't exist
    os.makedirs(CHROMA_DB_DIR, exist_ok=True)

    # Load documents
    all_json_data = load_all_json_files(JSON_FILES_DIR)
    if not all_json_data:
        print("No JSON data found in the directory!")
        return None, None

    documents = extract_text_from_json(all_json_data)
    current_hash = calculate_documents_hash(documents)
    saved_hash = load_hash()

    # Check if database exists and hash matches
    if os.path.exists(CHROMA_DB_DIR) and saved_hash == current_hash:
        print("Loading existing database...")
        with suppress_stdout():
            vectorstore = initialize_chroma_db(CHROMA_DB_DIR, EMBEDDING_MODEL_PATH)
        return vectorstore, None
    else:
        print("Initializing new database...")
        with suppress_stdout():
            vectorstore = initialize_chroma_db(CHROMA_DB_DIR, EMBEDDING_MODEL_PATH)
            vectorstore = add_documents_to_vectorstore(vectorstore, documents)
        save_hash(current_hash)
        return vectorstore, documents

def main():
    # Step 1: Initialize or load existing vectorstore
    vectorstore, documents = initialize_or_load_vectorstore()
    if vectorstore is None:
        return

    if documents:
        print(f"Processed {len(documents)} documents")
    else:
        print("Using existing database")

    # Step 2: Setup QA chain
    print("Setting up QA chain...")
    qa_chain = setup_qa_chain(vectorstore)

    # Step 3: Interactive question answering
    print("\nReady for questions!")
    while True:
        question = input("\nEnter your question (or 'quit' to exit): ")
        if question.lower() == 'quit':
            break

        print("\nProcessing your question...")
        with suppress_stdout():
            result = qa_chain({"query": question})

        print(f"\nQuestion: {question}")
        print(f"Answer: {result['result']}")
        print("\nSource Documents:")
        for i, doc in enumerate(result['source_documents'], 1):
            print(f"\nDocument {i}:")
            print(doc.page_content[:200] + "..." if len(doc.page_content) > 200 else doc.page_content)

if __name__ == "__main__":
    main()
```

Key optimizations and improvements:

1. **Database Persistence Check**:
   - Calculates a hash of all documents to track changes
   - Only rebuilds the database if the content has changed
   - Stores the hash in a file for future comparison

2. **Modular Functions**:
   - Separated the initialization logic into smaller, focused functions
   - Made the code more maintainable and easier to understand

3. **Performance Improvements**:
   - Avoids unnecessary reloading of documents
   - Skips embedding generation if the database already exists
   - Reuses existing ChromaDB if no changes are detected

4. **Better Status Messages**:
   - Clearer feedback about whether it's using existing data or creating new
   - Shows progress information only when relevant

To use this optimized version:

1. First run: Will create the database and save the document hash
2. Subsequent runs: 
   - If documents haven't changed: Uses existing database (much faster)
   - If documents have changed: Rebuilds the database automatically

The system will now be much more efficient for repeated use, especially when the document set remains the same. It will only rebuild the database when:
- It's the first run
- The documents have changed
- The database files are deleted

Let me know if you need any clarification or have questions about the optimizations!
