
I'll modify the code to process all JSON files from the `data` directory. Here's the updated implementation:

### **1. Update `config.py`**

```python
# config.py

# Path to JSON files directory
JSON_FILES_DIR = "data"  # Directory containing all JSON files

# ChromaDB settings
CHROMA_DB_DIR = "cache/chroma_db"

# Paths to your models
LLM_MODEL_PATH = r"C:\Users\omish\Downloads\JUNK\models\mistral-7b-instruct-v0.1.Q4_0.gguf"
EMBEDDING_MODEL_PATH = r"C:\Users\omish\Downloads\JUNK\models\gte-large"
```

### **2. Update `utils/json_processor.py`**

```python
# utils/json_processor.py

import json
import os
from typing import List, Dict

def get_all_json_files(directory: str) -> List[str]:
    """Get paths of all JSON files in the specified directory."""
    json_files = []
    for file in os.listdir(directory):
        if file.endswith('.json'):
            json_files.append(os.path.join(directory, file))
    return json_files

def load_json(file_path: str) -> List[Dict]:
    """Load JSON data from a file."""
    try:
        with open(file_path, "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception as e:
        print(f"Error loading {file_path}: {str(e)}")
        return []

def load_all_json_files(directory: str) -> List[Dict]:
    """Load data from all JSON files in the directory."""
    all_data = []
    json_files = get_all_json_files(directory)

    for file_path in json_files:
        print(f"Loading {file_path}...")
        data = load_json(file_path)
        if isinstance(data, list):
            all_data.extend(data)
        else:
            all_data.append(data)

    return all_data

def extract_text_from_json(json_data: List[Dict], key: str = "content") -> List[str]:
    """Extract text data from JSON based on a specific key."""
    texts = []
    for item in json_data:
        if isinstance(item, dict) and key in item:
            texts.append(item[key])
    return texts
```

### **3. Update `main.py`**

```python
# main.py

import os
from config import JSON_FILES_DIR, CHROMA_DB_DIR, LLM_MODEL_PATH, EMBEDDING_MODEL_PATH
from utils.json_processor import load_all_json_files, extract_text_from_json
from models.model_loader import load_llm_model, load_embedding_model
from database.vector_store import initialize_chroma_db, create_collection, add_documents_to_collection, query_collection
from agents.qa_agent import create_qa_agent

def main():
    # Step 1: Load all JSON data from directory
    print("Loading JSON data from directory...")
    all_json_data = load_all_json_files(JSON_FILES_DIR)

    if not all_json_data:
        print("No JSON data found in the directory!")
        return

    print(f"Loaded {len(all_json_data)} documents from JSON files")

    # Extract text from all documents
    documents = extract_text_from_json(all_json_data)
    print(f"Extracted {len(documents)} text documents")

    # Step 2: Load models
    print("Loading models...")
    llm_model = load_llm_model(LLM_MODEL_PATH)
    embedding_model = load_embedding_model(EMBEDDING_MODEL_PATH)

    # Step 3: Generate embeddings
    print("Generating embeddings...")
    embeddings = embedding_model.encode(documents)

    # Step 4: Initialize ChromaDB
    print("Initializing ChromaDB...")
    # Create cache directory if it doesn't exist
    os.makedirs(CHROMA_DB_DIR, exist_ok=True)
    chroma_client = initialize_chroma_db(CHROMA_DB_DIR)
    collection = create_collection(chroma_client, "json_collection")

    # Step 5: Add documents to ChromaDB
    print("Adding documents to ChromaDB...")
    add_documents_to_collection(collection, documents, embeddings)

    # Step 6: Create QA agent
    print("Creating QA agent...")
    retriever = collection.as_retriever()
    qa_agent = create_qa_agent(llm_model, retriever)

    # Step 7: Query the agent
    while True:
        question = input("\nEnter your question (or 'quit' to exit): ")
        if question.lower() == 'quit':
            break

        print("\nProcessing your question...")
        answer = qa_agent.run(question)
        print(f"\nQuestion: {question}")
        print(f"Answer: {answer}")

if __name__ == "__main__":
    main()
```

### **4. Project Structure**

```
your_project/
├── data/                  # Place all JSON files here
│   ├── sample1.json
│   ├── sample2.json
│   └── ...
├── cache/
│   └── chroma_db/        # ChromaDB persistence directory
├── models/
│   └── model_loader.py
├── database/
│   └── vector_store.py
├── agents/
│   └── qa_agent.py
├── utils/
│   └── json_processor.py
├── config.py
└── main.py
```

### **5. Key Changes and Features**

1. **Directory Processing**: The code now processes all JSON files in the `data` directory.
2. **Error Handling**: Added robust error handling for JSON file loading.
3. **Progress Feedback**: Added more detailed progress messages.
4. **Interactive Mode**: Added an interactive question-answering loop.
5. **Automatic Directory Creation**: The cache directory is created automatically.

### **6. Running the Project**

1. Create a `data` directory and place all your JSON files there.
2. Run the main script:
```bash
python main.py
```

### **7. Example Usage**

```bash
$ python main.py
Loading JSON data from directory...
Loading data/sample1.json...
Loading data/sample2.json...
Loaded 6 documents from JSON files
Extracted 6 text documents
Loading models...
Generating embeddings...
Initializing ChromaDB...
Adding documents to ChromaDB...
Creating QA agent...

Enter your question (or 'quit' to exit): What is Python?
Processing your question...

Question: What is Python?
Answer: Python is a versatile programming language used for web development, data analysis, artificial intelligence, and more.

Enter your question (or 'quit' to exit): quit
```

### **8. Notes**

- All JSON files in the `data` directory will be processed automatically.
- The ChromaDB data will be persistently stored in `cache/chroma_db`.
- The interactive mode allows you to ask multiple questions without restarting the program.
- Each JSON file should contain an array of objects with a "content" field (or specify a different key in `extract_text_from_json`).

Let me know if you need any clarification or have questions about the implementation!
